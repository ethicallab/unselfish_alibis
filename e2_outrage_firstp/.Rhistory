colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'col_donate','col_volunteer','col_protest','col_socMedia','col_shareLike','col_shareNonLike',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good data from the middle part of the raw data
for(i in 1:dim(data)[1]) {
curr <- data[i,20:75][!is.na(data[i,20:75])] #for a given row, get only the non NA values
d_subset[i,3:16] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- data[i,85:96][!is.na(data[i,85:96])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good data with first and last halves of the original data
data <- cbind(data[,18:19], d_subset, data[,76:81])
#rename 'person_cond' to 'victim_cond' and 'intention_cond' to 'program_cond'
data$victim_cond <- data$person_cond
data$program_cond <- data$intention_cond
#check that we have equal numbers for each of our various conditions
table(data$intention_cond)
table(data$person_cond)
# number of subjects before exclusions
n_original <- dim(data)[1]
n_original
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
#comprehension exclusions
data$comp1_recode <- ifelse(data$comp1==1, "intentional", ifelse(data$comp1==2, "random", "neither"))
data$comp2_recode <- ifelse(data$comp2==1, "driver", ifelse(data$comp2==2, "pedestri", "neither"))
#perform exclusions based on attention and comprehension checks
failed_program_comp <- sum(data$comp1_recode != data$intention_cond); failed_program_comp
failed_victim_comp <- sum(data$comp2_recode != data$person_cond); failed_victim_comp
data <- subset(data, (data$comp1_recode == data$intention_cond) &
(data$comp2_recode == data$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(data)[1]
n_after_exclusions
percent_excluded <- (n_original - n_after_exclusions)/n_original #34%
percent_excluded
## mean age and gender
mean(data$age,na.rm = TRUE)
table(data$gender)[2]/sum(table(data$gender))
table(data$intention_cond)
table(data$person_cond)
##================================================================================================================
##DATA PREP##
##================================================================================================================
#assign simple variable names to measures of interest
#and convert them to factor or numeric
#also aggregate outrage and collective action items
#conds
data$intention_cond <- as.factor(data$intention_cond)
data$intention_cond_num <- as.numeric(ifelse(data$intention_cond=="intentional", 1, 0))
data$person_cond <- as.factor(data$person_cond)
data$person_cond_num <- as.numeric(ifelse(data$person_cond=="pedestri", 1, 0))
#blame
blame_man <- as.numeric(data$blame_man)
data$blame_man <- as.numeric(data$blame_man)
blame_av <- as.numeric(data$blame_av)
data$blame_av <- as.numeric(data$blame_av)
blame_company <- as.numeric(data$blame_company)
data$blame_company <- as.numeric(data$blame_company)
#outrage
outrage_anger <- as.numeric(data$outrage_anger)
outrage_punish <- as.numeric(data$outrage_punish)
outrage_wrong <- as.numeric(data$outrage_wrong)
outrage_mat <- array(0,dim=c(dim(data)[1],3)) #get cronbach's alpha, then average items
outrage_mat[,1] <- outrage_anger
outrage_mat[,2] <- outrage_punish
outrage_mat[,3] <- outrage_wrong
cronbach.alpha(outrage_mat) #0.93
outrage <- rowMeans(outrage_mat)
data$outrage <- outrage
#collective action
col_volunteer <- as.numeric(data$col_volunteer)
col_protest <- as.numeric(data$col_protest)
col_socMedia <- as.numeric(data$col_socMedia)
col_shareLike <- as.numeric(data$col_shareLike)
col_shareNonLike <- as.numeric(data$col_shareNonLike)
col_mat <- array(0,dim=c(dim(data)[1],5)) #get cronbach's alpha, then average items
col_mat[,1] <- col_volunteer
col_mat[,2] <- col_protest
col_mat[,3] <- col_socMedia
col_mat[,4] <- col_shareLike
col_mat[,5] <- col_shareNonLike
cronbach.alpha(col_mat) #0.85
col_action <- rowMeans(col_mat)
data$col_action <- col_action
#export csv for mediation analysis in SPSS
write.csv(data,"spss_data_e3.csv", row.names = FALSE)
##================================================================================================================
##ANALYSIS##
##================================================================================================================
#define some labels
intention_labels <- c('intentional', 'random')
person_labels <- c('driver', 'pedestrian')
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- lm(blame_man ~ person_cond*intention_cond, data=data)
summary(blame_man_mod)
tapply(blame_man, person_cond)
# intentional pedestrian v. random driver
var.test(data$blame_man[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_man[data$intention_cond == 'random' & data$person_cond == 'driver'])
blame_company_t <- t.test(data$blame_man[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_man[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
blame_company_t
# (1.2) BLAME AV -----------------------------------------------------
blame_av_mod <- lm(blame_av ~ person_cond*intention_cond, data=data)
summary(blame_av_mod)
var.test(data$blame_av[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_av[data$intention_cond == 'random' & data$person_cond == 'driver'])
blame_av_t <- t.test(data$blame_av[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_av[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
blame_av_t
# (1.3) BLAME FIRM ----------------------------------------------------
blame_company_mod <- lm(blame_company ~ person_cond*intention_cond, data=data)
summary(blame_company_mod)
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E4, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
##================================================================================================================
##IMPORT & PRE-PROCESS DATA##
##================================================================================================================
#get subjects from e1
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
#read data
data <- read.csv('data.csv')
data <- subset(data, data$att1==2 & data$att2==2)
#define new data frame that we'll extract preprocessed data into
d_subset <- array(dim=c(dim(data)[1], 10))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good data from the middle part of the raw data
for(i in 1:dim(data)[1]) {
curr <- data[i,20:51][!is.na(data[i,20:51])] #for a given row, get only the non NA values
d_subset[i,3:10] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- data[i,61:68][!is.na(data[i,61:68])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good data with first and last halves of the original data
data <- cbind(data[,18:19], d_subset, data[,52:57])
#check that we have equal numbers for each of our various conditions
table(data$intention_cond)
table(data$person_cond)
# number of subjects before exclusions
n_original <- dim(data)[1]
n_original
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
#comprehension exclusions
data$comp1_recode <- ifelse(data$comp1==1, "intentional", ifelse(data$comp1==2, "random", "neither"))
data$comp2_recode <- ifelse(data$comp2==1, "driver", ifelse(data$comp2==2, "pedestri", "neither"))
excluded_program <- sum(data$comp1_recode != data$intention_cond); excluded_program
excluded_victim <- sum(data$comp2_recode != data$person_cond); excluded_victim
#perform exclusions based on attention and comprehension checks
data <- subset(data, (data$comp1_recode == data$intention_cond) &
(data$comp2_recode == data$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(data)[1]
n_after_exclusions
percent_excluded <- (n_original - n_after_exclusions)/n_original #34%
percent_excluded
## mean age and gender
mean(as.numeric(data$age),na.rm = TRUE)
table(data$gender)[2]/sum(table(data$gender))
table(data$intention_cond)
table(data$person_cond)
##================================================================================================================
##DATA PREP##
##================================================================================================================
#assign simple variable names to measures of interest
#and convert them to factor or numeric
#also aggregate outrage and collective action items
#conds
data$intention_cond <- as.factor(data$intention_cond)
data$intention_cond_num <- as.numeric(ifelse(data$intention_cond=="intentional", 1, 0))
data$person_cond <- as.factor(data$person_cond)
data$person_cond_num <- as.numeric(ifelse(data$person_cond=="pedestri", 1, 0))
#outrage
outrage_anger <- as.numeric(data$outrage_anger)
outrage_punish <- as.numeric(data$outrage_punish)
outrage_wrong <- as.numeric(data$outrage_wrong)
outrage_mat <- array(0,dim=c(dim(data)[1],3)) #get cronbach's alpha, then average items
outrage_mat[,1] <- outrage_anger
outrage_mat[,2] <- outrage_punish
outrage_mat[,3] <- outrage_wrong
cronbach.alpha(outrage_mat) #0.93
outrage <- rowMeans(outrage_mat)
data$outrage <- outrage
#collective action
col_volunteer <- as.numeric(data$col_volunteer)
col_protest <- as.numeric(data$col_protest)
col_socMedia <- as.numeric(data$col_socMedia)
col_shareLike <- as.numeric(data$col_shareLike)
col_shareNonLike <- as.numeric(data$col_shareNonLike)
col_mat <- array(0,dim=c(dim(data)[1],5)) #get cronbach's alpha, then average items
col_mat[,1] <- col_volunteer
col_mat[,2] <- col_protest
col_mat[,3] <- col_socMedia
col_mat[,4] <- col_shareLike
col_mat[,5] <- col_shareNonLike
cronbach.alpha(col_mat) #0.85
col_action <- rowMeans(col_mat)
data$col_action <- col_action
#export csv for mediation analysis in SPSS
write.csv(data,"spss_data_e4.csv", row.names = FALSE)
##================================================================================================================
##ANALYSIS##
##================================================================================================================
#define some labels
intention_labels <- c('intentional', 'random')
person_labels <- c('driver', 'pedestrian')
## (1.1) BLAME HUMAN ---------------------------------
blame_man_mod <- lm(blame_man ~ person_cond*intention_cond, data=data)
summary(blame_man_mod)
# intentional pedestrian v. random driver
var.test(data$blame_man[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_man[data$intention_cond == 'random' & data$person_cond == 'driver'])
blame_man_t <- t.test(data$blame_man[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_man[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
blame_man_t
## (1.2) BLAME AV -----------------------------------
blame_av_mod <- lm(blame_av ~ person_cond*intention_cond, data=data)
summary(blame_av_mod)
tapply(data$blame_av, data$person_cond, mean)
# intentional pedestrian v. random driver
var.test(data$blame_av[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_av[data$intention_cond == 'random' & data$person_cond == 'driver'])
blame_av_t <- t.test(data$blame_av[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_av[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
blame_av_t
## (1.3) BLAME FIRM  ----------------------------
blame_company_mod <- lm(blame_company ~ person_cond_num*intention_cond_num, data=data)
summary(blame_company_mod)
## (2) OUTRAGE COMPANY --------------------------
outrage_mod <- lm(outrage ~ person_cond_num*intention_cond_num, data=data)
summary(outrage_mod)
## (2) OUTRAGE COMPANY --------------------------
outrage_mod <- lm(outrage ~ person_cond_num*intention_cond_num, data=data)
summary(outrage_mod)
## (2) OUTRAGE COMPANY --------------------------
outrage_mod <- lm(outrage ~ person_cond_num*intention_cond_num, data=data)
summary(outrage_mod)
## (2) OUTRAGE COMPANY --------------------------
outrage_mod <- lm(outrage ~ person_cond_num*intention_cond_num, data=data)
summary(outrage_mod)
# intentional pedestrian v.  driver
var.test(data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'driver'])
outrage_1_t <- t.test(data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
outrage_1_t
var.test(data$outrage[data$intention_cond == 'random' & data$person_cond == 'pedestri'],
data$outrage[data$intention_cond == 'random' & data$person_cond == 'driver'])
outrage_2_t <- t.test(data$outrage[data$intention_cond == 'random' & data$person_cond == 'pedestri'],
data$outrage[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
outrage_2_t
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E4, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
##================================================================================================================
##IMPORT & PRE-PROCESS DATA##
##================================================================================================================
#get subjects from e1
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
#read data
data <- read.csv('data.csv')
data <- subset(data, data$att1==2 & data$att2==2)
#define new data frame that we'll extract preprocessed data into
d_subset <- array(dim=c(dim(data)[1], 10))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good data from the middle part of the raw data
for(i in 1:dim(data)[1]) {
curr <- data[i,20:51][!is.na(data[i,20:51])] #for a given row, get only the non NA values
d_subset[i,3:10] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- data[i,61:68][!is.na(data[i,61:68])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good data with first and last halves of the original data
data <- cbind(data[,18:19], d_subset, data[,52:57])
#check that we have equal numbers for each of our various conditions
table(data$intention_cond)
table(data$person_cond)
# number of subjects before exclusions
n_original <- dim(data)[1]
n_original
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
#comprehension exclusions
data$comp1_recode <- ifelse(data$comp1==1, "intentional", ifelse(data$comp1==2, "random", "neither"))
data$comp2_recode <- ifelse(data$comp2==1, "driver", ifelse(data$comp2==2, "pedestri", "neither"))
excluded_program <- sum(data$comp1_recode != data$intention_cond); excluded_program
excluded_victim <- sum(data$comp2_recode != data$person_cond); excluded_victim
#perform exclusions based on attention and comprehension checks
data <- subset(data, (data$comp1_recode == data$intention_cond) &
(data$comp2_recode == data$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(data)[1]
n_after_exclusions
percent_excluded <- (n_original - n_after_exclusions)/n_original #34%
percent_excluded
## mean age and gender
mean(as.numeric(data$age),na.rm = TRUE)
table(data$gender)[2]/sum(table(data$gender))
table(data$intention_cond)
table(data$person_cond)
##================================================================================================================
##DATA PREP##
##================================================================================================================
#assign simple variable names to measures of interest
#and convert them to factor or numeric
#also aggregate outrage and collective action items
#conds
data$intention_cond <- as.factor(data$intention_cond)
data$int_n <- as.numeric(ifelse(data$intention_cond=="intentional", 1, 0))
data$person_cond <- as.factor(data$person_cond)
data$vic_n <- as.numeric(ifelse(data$person_cond=="pedestri", 1, 0))
#outrage
outrage_anger <- as.numeric(data$outrage_anger)
outrage_punish <- as.numeric(data$outrage_punish)
outrage_wrong <- as.numeric(data$outrage_wrong)
outrage_mat <- array(0,dim=c(dim(data)[1],3)) #get cronbach's alpha, then average items
outrage_mat[,1] <- outrage_anger
outrage_mat[,2] <- outrage_punish
outrage_mat[,3] <- outrage_wrong
cronbach.alpha(outrage_mat) #0.93
outrage <- rowMeans(outrage_mat)
data$outrage <- outrage
#collective action
col_volunteer <- as.numeric(data$col_volunteer)
col_protest <- as.numeric(data$col_protest)
col_socMedia <- as.numeric(data$col_socMedia)
col_shareLike <- as.numeric(data$col_shareLike)
col_shareNonLike <- as.numeric(data$col_shareNonLike)
col_mat <- array(0,dim=c(dim(data)[1],5)) #get cronbach's alpha, then average items
col_mat[,1] <- col_volunteer
col_mat[,2] <- col_protest
col_mat[,3] <- col_socMedia
col_mat[,4] <- col_shareLike
col_mat[,5] <- col_shareNonLike
cronbach.alpha(col_mat) #0.85
col_action <- rowMeans(col_mat)
data$col_action <- col_action
#export csv for mediation analysis in SPSS
data_spss <- data
data_spss$blame_f <- data$blame_company
write.csv(data,"spss_data_e4.csv", row.names = FALSE)
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E4, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
##================================================================================================================
##IMPORT & PRE-PROCESS DATA##
##================================================================================================================
#get subjects from e1
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
#read data
data <- read.csv('data.csv')
data <- subset(data, data$att1==2 & data$att2==2)
#define new data frame that we'll extract preprocessed data into
d_subset <- array(dim=c(dim(data)[1], 10))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good data from the middle part of the raw data
for(i in 1:dim(data)[1]) {
curr <- data[i,20:51][!is.na(data[i,20:51])] #for a given row, get only the non NA values
d_subset[i,3:10] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- data[i,61:68][!is.na(data[i,61:68])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good data with first and last halves of the original data
data <- cbind(data[,18:19], d_subset, data[,52:57])
#check that we have equal numbers for each of our various conditions
table(data$intention_cond)
table(data$person_cond)
# number of subjects before exclusions
n_original <- dim(data)[1]
n_original
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
#comprehension exclusions
data$comp1_recode <- ifelse(data$comp1==1, "intentional", ifelse(data$comp1==2, "random", "neither"))
data$comp2_recode <- ifelse(data$comp2==1, "driver", ifelse(data$comp2==2, "pedestri", "neither"))
excluded_program <- sum(data$comp1_recode != data$intention_cond); excluded_program
excluded_victim <- sum(data$comp2_recode != data$person_cond); excluded_victim
#perform exclusions based on attention and comprehension checks
data <- subset(data, (data$comp1_recode == data$intention_cond) &
(data$comp2_recode == data$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(data)[1]
n_after_exclusions
percent_excluded <- (n_original - n_after_exclusions)/n_original #34%
percent_excluded
## mean age and gender
mean(as.numeric(data$age),na.rm = TRUE)
table(data$gender)[2]/sum(table(data$gender))
table(data$intention_cond)
table(data$person_cond)
##================================================================================================================
##DATA PREP##
##================================================================================================================
#assign simple variable names to measures of interest
#and convert them to factor or numeric
#also aggregate outrage and collective action items
#conds
data$intention_cond <- as.factor(data$intention_cond)
data$int_n <- as.numeric(ifelse(data$intention_cond=="intentional", 1, 0))
data$person_cond <- as.factor(data$person_cond)
data$vic_n <- as.numeric(ifelse(data$person_cond=="pedestri", 1, 0))
#outrage
outrage_anger <- as.numeric(data$outrage_anger)
outrage_punish <- as.numeric(data$outrage_punish)
outrage_wrong <- as.numeric(data$outrage_wrong)
outrage_mat <- array(0,dim=c(dim(data)[1],3)) #get cronbach's alpha, then average items
outrage_mat[,1] <- outrage_anger
outrage_mat[,2] <- outrage_punish
outrage_mat[,3] <- outrage_wrong
cronbach.alpha(outrage_mat) #0.93
outrage <- rowMeans(outrage_mat)
data$outrage <- outrage
#collective action
col_volunteer <- as.numeric(data$col_volunteer)
col_protest <- as.numeric(data$col_protest)
col_socMedia <- as.numeric(data$col_socMedia)
col_shareLike <- as.numeric(data$col_shareLike)
col_shareNonLike <- as.numeric(data$col_shareNonLike)
col_mat <- array(0,dim=c(dim(data)[1],5)) #get cronbach's alpha, then average items
col_mat[,1] <- col_volunteer
col_mat[,2] <- col_protest
col_mat[,3] <- col_socMedia
col_mat[,4] <- col_shareLike
col_mat[,5] <- col_shareNonLike
cronbach.alpha(col_mat) #0.85
col_action <- rowMeans(col_mat)
data$col_action <- col_action
#export csv for mediation analysis in SPSS
data_spss <- data
data_spss$blame_f <- data$blame_company
write.csv(data_spss,"spss_data_e4.csv", row.names = FALSE)
head(spss_data_e4)
head(data_spss)
