#HDV, forced v. unforced
human_only <- table(d$choice_dicot[d$agent_cond=="human"], d$forced_cond[d$agent_cond=="human"])
human_only_mod <- chisq.test(human_only); human_only_mod
n_human_subj <- sum(human_only)
sum(av_only) #num av subjects
sum(human_only) #num human subjects
490+399
#AV, forced v. unforced
av_only <- table(d$choice_dicot[d$agent_cond=="AV"], d$forced_cond[d$agent_cond=="AV"])
av_only_mod <- chisq.test(av_only); av_only_mod
#AV, forced v. unforced
av_only <- table(d$choice_dicot[d$agent_cond=="AV"], d$forced_cond[d$agent_cond=="AV"])
av_only_mod <- chisq.test(av_only); av_only_mod
#HDV, forced v. unforced
human_only <- table(d$choice_dicot[d$agent_cond=="human"], d$forced_cond[d$agent_cond=="human"])
human_only_mod <- chisq.test(human_only); human_only_mod
table(d$forced_cond)
table(d$agent_cond, d$forced_cond)
#make arrays for plotting infinity item
choice_mat <- array(0,dim=c(3,4))
colnames(choice_mat) <- c('vehicle_num', 'forced_num', 'choice', 'proportion')
choice_mat <- as.data.frame(choice_mat, stringsAsFactors=FALSE)
counter <- 1
for(i in 1:2) {
for(j in 1:2) {
for(k in 1:3) {
choice_mat[counter,] <- c(i, j, k, length(d$choice[d$vehicle_num==i & d$forced_num==j & d$choice == k])/
length(d$choice[d$vehicle_num==i & d$forced_num==j])*100)
counter <- counter + 1
}
}
}
forced_labels <- c("Two", "Three")
choice_labels <- c("Save Pedestrian", "Save Passenger", "Egalitarian")
choice_car <- subset(choice_mat, choice_mat$vehicle_num==1)
choice_car
choice_av <- subset(choice_mat, choice_mat$vehicle_num==2)
choice_av <- subset(choice_mat, choice_mat$vehicle_num==2)
choice_av
p1 <-ggplot(choice_car,aes(x=factor(forced_num),y=as.numeric(proportion),fill=factor(choice)),color=factor(choice)) +
stat_summary(position=position_dodge(),geom="bar")+
theme_bw()+coord_cartesian(ylim=c(1,100))
p1 <- p1+theme(text = element_text(size=16),panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
scale_x_discrete(breaks = 1:length(forced_labels), labels=forced_labels)+
ggtitle("Human-Driven Vehicle")+
scale_fill_manual(values = c("#cccccc", "#989898", "#333333"),name= "Choice:",
labels=choice_labels, guide = guide_legend(reverse = FALSE))+
theme_classic()+
xlab("") + ylab ("") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size=14))+
theme(axis.text.y = element_text(size=14))+
theme(plot.title = element_text(size=20, hjust=0.5))+
theme(legend.text = element_text(size=15))+
theme(legend.title = element_text(size=16))
p1
p2 <-ggplot(choice_av,aes(x=factor(forced_num),y=as.numeric(proportion),fill=factor(choice)),color=factor(choice)) +
stat_summary(position=position_dodge(),geom="bar")+
theme_bw()+coord_cartesian(ylim=c(1,100))
p2 <- p2+theme(text = element_text(size=16),panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
scale_x_discrete(breaks = 1:length(forced_labels), labels=forced_labels)+
ggtitle("Autonomous Vehicle")+
scale_fill_manual(values = c("#cccccc", "#989898", "#333333"),name= "Choice:",
labels=choice_labels, guide = guide_legend(reverse = FALSE))+
theme_classic()+
xlab("") + ylab ("") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size=14))+
theme(axis.text.y = element_text(size=14))+
theme(plot.title = element_text(size=20, hjust=0.5))+
theme(legend.text = element_text(size=15))+
theme(legend.title = element_text(size=14))
p2
dev.new(width=13,height=6,noRStudioGD = TRUE)
figure<-ggarrange(p1, p2, nrow=1,ncol=2,common.legend = TRUE, legend="top", vjust = 1.0, hjust=0.5)
annotate_figure(figure,left = text_grob("Proportion Agreement", color="black", face ="plain",size=20, rot=90),
bottom = text_grob("Number of Response Options", color="black", face ="plain",size=20))
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E3a, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
source('../common_functions/process.R')
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E3a, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
source('../common_functions/process.R')
##================================================================================================================
##IMPORT & PRE-PROCESS DATA##
##================================================================================================================
#read data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('data.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
#define new data frame that we'll extract preprocessed data into
d_subset <- array(dim=c(dim(d)[1], 16))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'col_donate','col_volunteer','col_protest','col_socMedia','col_shareLike','col_shareNonLike',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E3a, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
source('../common_functions/process.R')
##================================================================================================================
##IMPORT & PRE-PROCESS d##
##================================================================================================================
#read d
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('d.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
#define new d frame that we'll extract preprocessed d into
d_subset <- array(dim=c(dim(d)[1], 16))
#read d
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('d.csv')
d <- read.csv('e3a_data.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
# Julian De Freitas, 2021
# Analysis script for De Freitas
# E3a, Should Automated Vehicles Favor Passengers Over Pedestrians?
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2', #plotting
'ggsignif', #plotting significance bars
'lme4', #functions for fitting linear regression modesl
'ggforce', #make ggplot even fancier
'ggpubr', #arrange plots in a grid, if neededd
'ltm', #probably not using..
'simr', # power analysis for mixed models
'compute.es', # effect size package
'effsize', # another effect size package
'pwr', #package for power calculation
)
library("lmerTest")
source('../common_functions/process.R')
##================================================================================================================
##IMPORT & PRE-PROCESS d##
##================================================================================================================
#read d
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('e3a_data.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
#define new d frame that we'll extract preprocessed d into
d_subset <- array(dim=c(dim(d)[1], 16))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'col_donate','col_volunteer','col_protest','col_socMedia','col_shareLike','col_shareNonLike',
'comp1','comp2')
d_subset <- as.d.frame(d_subset, stringsAsFactors=FALSE)
#read d
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('e3a_data.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
#define new d frame that we'll extract preprocessed d into
d_subset <- array(dim=c(dim(d)[1], 16))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'col_donate','col_volunteer','col_protest','col_socMedia','col_shareLike','col_shareNonLike',
'comp1','comp2')
d_subset <- as.d.frame(d_subset, stringsAsFactors=FALSE)
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good d from the middle part of the raw d
for(i in 1:dim(d)[1]) {
curr <- d[i,20:75][!is.na(d[i,20:75])] #for a given row, get only the non NA values
d_subset[i,3:16] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- d[i,85:96][!is.na(d[i,85:96])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good d with first and last halves of the original d
d <- cbind(d[,18:19], d_subset, d[,76:81])
#rename 'person_cond' to 'victim_cond' and 'intention_cond' to 'program_cond'
d$victim_cond <- d$person_cond
d$program_cond <- d$intention_cond
#read d
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('e3a_data.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
#define new d frame that we'll extract preprocessed d into
d_subset <- array(dim=c(dim(d)[1], 16))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'col_donate','col_volunteer','col_protest','col_socMedia','col_shareLike','col_shareNonLike',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good d from the middle part of the raw d
for(i in 1:dim(d)[1]) {
curr <- d[i,20:75][!is.na(d[i,20:75])] #for a given row, get only the non NA values
d_subset[i,3:16] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- d[i,85:96][!is.na(d[i,85:96])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good d with first and last halves of the original d
d <- cbind(d[,18:19], d_subset, d[,76:81])
#rename 'person_cond' to 'victim_cond' and 'intention_cond' to 'program_cond'
d$victim_cond <- d$person_cond
d$program_cond <- d$intention_cond
#check that we have equal numbers for each of our various conditions
table(d$intention_cond)
table(d$person_cond)
# number of subjects before exclusions
n_original <- dim(d)[1]
n_original
#comprehension exclusions
d$comp1_recode <- ifelse(d$comp1==1, "intentional", ifelse(d$comp1==2, "random", "neither"))
d$comp2_recode <- ifelse(d$comp2==1, "driver", ifelse(d$comp2==2, "pedestri", "neither"))
#perform exclusions based on attention and comprehension checks
failed_program_comp <- sum(d$comp1_recode != d$intention_cond); failed_program_comp
failed_victim_comp <- sum(d$comp2_recode != d$person_cond); failed_victim_comp
d <- subset(d, (d$comp1_recode == d$intention_cond) &
(d$comp2_recode == d$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(d)[1]; n_after_exclusions
#comprehension exclusions
d$comp1_recode <- ifelse(d$comp1==1, "intentional", ifelse(d$comp1==2, "random", "neither"))
d$comp2_recode <- ifelse(d$comp2==1, "driver", ifelse(d$comp2==2, "pedestri", "neither"))
#perform exclusions based on attention and comprehension checks
failed_program_comp <- sum(d$comp1_recode != d$intention_cond); failed_program_comp
failed_victim_comp <- sum(d$comp2_recode != d$person_cond); failed_victim_comp
d <- subset(d, (d$comp1_recode == d$intention_cond) &
(d$comp2_recode == d$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(d)[1]; n_after_exclusions
percent_excluded <- (n_original - n_after_exclusions)/n_original; percent_excluded
## mean age and gender
mean(d$age,na.rm = TRUE)
table(d$gender)[2]/sum(table(d$gender))
table(d$intention_cond)
table(d$person_cond)
#read d
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directoy to current directory
d <- read.csv('e3a_data.csv')
dim(d)
d <- subset(d, d$att1==2 & d$att2==2)
#define new d frame that we'll extract preprocessed d into
d_subset <- array(dim=c(dim(d)[1], 16))
colnames(d_subset) <- c('intention_cond','person_cond',
'blame_man','blame_av','blame_company','outrage_anger','outrage_punish','outrage_wrong',
'col_donate','col_volunteer','col_protest','col_socMedia','col_shareLike','col_shareNonLike',
'comp1','comp2')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
#extract the good d from the middle part of the raw d
for(i in 1:dim(d)[1]) {
curr <- d[i,20:75][!is.na(d[i,20:75])] #for a given row, get only the non NA values
d_subset[i,3:16] <- as.numeric(curr[curr!= ""]) #and only the non-empty values
cond_names <- d[i,85:96][!is.na(d[i,85:96])]
cond_names <- cond_names[cond_names!= ""]
d_subset[i,1] <- strsplit(cond_names[[1]], "_")[[1]][1]
d_subset[i,2] <- strsplit(strsplit(cond_names[[1]], "_")[[1]][2], '\\|')[[1]][1]
}
#merge good d with first and last halves of the original d
d <- cbind(d[,18:19], d_subset, d[,76:81])
#rename 'person_cond' to 'victim_cond' and 'intention_cond' to 'program_cond'
d$victim_cond <- d$person_cond
d$program_cond <- d$intention_cond
#check that we have equal numbers for each of our various conditions
table(d$intention_cond)
table(d$person_cond)
# number of subjects before exclusions
n_original <- dim(d)[1]
n_original
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
#comprehension exclusions
d$comp1_recode <- ifelse(d$comp1==1, "intentional", ifelse(d$comp1==2, "random", "neither"))
d$comp2_recode <- ifelse(d$comp2==1, "driver", ifelse(d$comp2==2, "pedestri", "neither"))
#perform exclusions based on attention and comprehension checks
failed_program_comp <- sum(d$comp1_recode != d$intention_cond); failed_program_comp
failed_victim_comp <- sum(d$comp2_recode != d$person_cond); failed_victim_comp
d <- subset(d, (d$comp1_recode == d$intention_cond) &
(d$comp2_recode == d$person_cond))
#number of subjects after exclusions
n_after_exclusions <- dim(d)[1]; n_after_exclusions
percent_excluded <- (n_original - n_after_exclusions)/n_original; percent_excluded
## mean age and gender
mean(d$age,na.rm = TRUE)
table(d$gender)[2]/sum(table(d$gender))
table(d$intention_cond)
table(d$person_cond)
#conds
d$intention_cond <- as.factor(d$intention_cond)
d$intention_cond_num <- as.numeric(ifelse(d$intention_cond=="intentional", 1, 0))
d$person_cond <- as.factor(d$person_cond)
d$person_cond_num <- as.numeric(ifelse(d$person_cond=="pedestri", 1, 0))
#blame
blame_man <- as.numeric(d$blame_man)
d$blame_man <- as.numeric(d$blame_man)
blame_av <- as.numeric(d$blame_av)
d$blame_av <- as.numeric(d$blame_av)
blame_company <- as.numeric(d$blame_company)
#conds
d$intention_cond <- as.factor(d$intention_cond)
d$intention_cond_num <- as.numeric(ifelse(d$intention_cond=="intentional", 1, 0))
d$person_cond <- as.factor(d$person_cond)
d$person_cond_num <- as.numeric(ifelse(d$person_cond=="pedestri", 1, 0))
#blame
blame_man <- as.numeric(d$blame_man)
d$blame_man <- as.numeric(d$blame_man)
blame_av <- as.numeric(d$blame_av)
d$blame_av <- as.numeric(d$blame_av)
blame_company <- as.numeric(d$blame_company)
d$blame_company <- as.numeric(d$blame_company)
#outrage
outrage_anger <- as.numeric(d$outrage_anger)
outrage_punish <- as.numeric(d$outrage_punish)
outrage_wrong <- as.numeric(d$outrage_wrong)
outrage_mat <- array(0,dim=c(dim(d)[1],3)) #get cronbach's alpha, then average items
outrage_mat[,1] <- outrage_anger
outrage_mat[,2] <- outrage_punish
outrage_mat[,3] <- outrage_wrong
cronbach.alpha(outrage_mat) #0.93
outrage <- rowMeans(outrage_mat)
d$outrage <- outrage
#collective action
col_volunteer <- as.numeric(d$col_volunteer)
col_protest <- as.numeric(d$col_protest)
col_socMedia <- as.numeric(d$col_socMedia)
col_shareLike <- as.numeric(d$col_shareLike)
col_shareNonLike <- as.numeric(d$col_shareNonLike)
col_mat <- array(0,dim=c(dim(d)[1],5)) #get cronbach's alpha, then average items
col_mat[,1] <- col_volunteer
col_mat[,2] <- col_protest
col_mat[,3] <- col_socMedia
col_mat[,4] <- col_shareLike
col_mat[,5] <- col_shareNonLike
cronbach.alpha(col_mat) #0.85
col_action <- rowMeans(col_mat)
d$col_action <- col_action
#define some labels
intention_labels <- c('intentional', 'random')
person_labels <- c('driver', 'pedestrian')
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- lm(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
# (1.3) BLAME FIRM ----------------------------------------------------
blame_company_mod <- lm(blame_company ~ person_cond*intention_cond, d=d)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- aov(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
is.numeric(blame_man)
is.factor(d$person_cond)
is.factor(d$intention_cond)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- lm(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- lm(blame_man ~ person_cond_num*intention_cond_num, d=d)
summary(blame_man_mod)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- aov(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- aov(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- aov(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
# (1.2) BLAME AV -----------------------------------------------------
blame_av_mod <- aov(blame_av ~ person_cond*intention_cond, d=d)
summary(blame_av_mod)
# (1.3) BLAME FIRM ----------------------------------------------------
blame_company_mod <- aov(blame_company ~ person_cond*intention_cond, d=d)
summary(blame_company_mod)
## VIOLIN PLOTS ##
d$intention_cond <- as.factor(d$intention_cond)
d$blame_company <- as.numeric(d$blame_company)
d$outrage <- as.numeric(d$outrage)
pref_graph_labels <- c("Driver", "Pedestrian")
# (0) BLAME HUMAN
p0_1<-ggplot(d,aes(x=factor(intention_cond),y=blame_man,fill=factor(person_cond)),color=factor(person_cond)) +
theme_bw()+coord_cartesian(ylim=c(25,100))
p0_1<- p0_1+theme(text = element_text(size=16),panel.grid.major = element_blank(),panel.grid.minor = element_blank())+
scale_x_discrete(labels=c("Deliberate", "Random"))+
ggtitle("Blame of Human")+
scale_fill_manual(values = c("#56B4E9", "#009E73"),name= "Target Killed:",
labels=pref_graph_labels)+
ylab ("") + xlab("")+
theme_classic()+
theme(axis.text.x = element_text(size=12))+
theme(axis.text.y = element_text(size=10))+
theme(plot.title = element_text(size=14, hjust=0.5))+
theme(legend.text = element_text(size=15))+
theme(legend.title = element_text(size=16))+
geom_violin(width=0.9, alpha=0.38, size=0.75)+
geom_sina(alpha=0.6, size=0.95, color = "#999999")+
stat_summary(fun.d = "mean_se", color = "black",
size=0.4, fun.args = list(mult = 1),
position = position_dodge(width = 0.9))+
stat_summary(fun.d = "mean_se", color = "black",
fun.args = list(mult = 1),
position = position_dodge(width = 0.9),
geom="errorbar", width = 0.2)
p0_1
p0_2<-ggplot(d,aes(x=factor(intention_cond),y=blame_av,fill=factor(person_cond)),color=factor(person_cond)) +
theme_bw()+coord_cartesian(ylim=c(25,100))
p0_2<- p0_2+theme(text = element_text(size=16),panel.grid.major = element_blank(),panel.grid.minor = element_blank())+
scale_x_discrete(labels=c("Deliberate", "Random"))+
ggtitle("Blame of AV")+
scale_fill_manual(values = c("#56B4E9", "#009E73"),name= "Target Killed:",
labels=pref_graph_labels)+
ylab ("") + xlab("")+
theme_classic()+
theme(axis.text.x = element_text(size=12))+
theme(axis.text.y = element_text(size=10))+
theme(plot.title = element_text(size=14, hjust=0.5))+
theme(legend.text = element_text(size=15))+
theme(legend.title = element_text(size=16))+
geom_violin(width=0.9, alpha=0.38, size=0.75)+
geom_sina(alpha=0.6, size=0.95, color = "#999999")+
stat_summary(fun.d = "mean_se", color = "black",
size=0.4, fun.args = list(mult = 1),
position = position_dodge(width = 0.9))+
stat_summary(fun.d = "mean_se", color = "black",
fun.args = list(mult = 1),
position = position_dodge(width = 0.9),
geom="errorbar", width = 0.2)
p0_2
p1_1<-ggplot(d,aes(x=factor(intention_cond),y=blame_company,fill=factor(person_cond)),color=factor(person_cond)) +
theme_bw()+coord_cartesian(ylim=c(25,100))
p1_1<- p1_1+theme(text = element_text(size=16),panel.grid.major = element_blank(),panel.grid.minor = element_blank())+
scale_x_discrete(labels=c("Deliberate", "Random"))+
ggtitle("Blame of Firm")+
scale_fill_manual(values = c("#56B4E9", "#009E73"),name= "Target Killed:",
labels=pref_graph_labels)+
ylab ("") + xlab("")+
theme_classic()+
theme(axis.text.x = element_text(size=12))+
theme(axis.text.y = element_text(size=10))+
theme(plot.title = element_text(size=14, hjust=0.5))+
theme(legend.text = element_text(size=15))+
theme(legend.title = element_text(size=16))+
geom_violin(width=0.9, alpha=0.38, size=0.75)+
geom_sina(alpha=0.6, size=0.95, color = "#999999")+
stat_summary(fun.d = "mean_se", color = "black",
size=0.4, fun.args = list(mult = 1),
position = position_dodge(width = 0.9))+
stat_summary(fun.d = "mean_se", color = "black",
fun.args = list(mult = 1),
position = position_dodge(width = 0.9),
geom="errorbar", width = 0.2)
p1_1
is.factor(d$person_cond)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- aov(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
# (1.2) BLAME AV -----------------------------------------------------
blame_av_mod <- aov(blame_av ~ person_cond*intention_cond, d=d)
summary(blame_av_mod)
# (1.3) BLAME FIRM ----------------------------------------------------
blame_company_mod <- aov(blame_company ~ person_cond*intention_cond, d=d)
summary(blame_company_mod)
# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- aov(blame_man ~ person_cond*intention_cond, d=d)
summary(blame_man_mod)
